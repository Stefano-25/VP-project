{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\servi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset,ConcatDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOWNLOAD THE FACEFORENSIC'S DATASET FROM KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"kaggle\" non ï¿½ riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n"
     ]
    }
   ],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = \"stefanoservillo\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \"d820211db8d6f4de9f2656d1eb4c2c38\" \n",
    "\n",
    "!kaggle datasets download -d ciplab/real-and-fake-face-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip real-and-fake-face-detection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAKE THE DATASET AND DIVIDE IT INTO TRAIN-SET AND VAL-SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='real_and_fake_face'\n",
    "BATCH_SIZE=32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "dataset=ImageFolder(path,transform=transfrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,val_set=train_test_split(dataset,test_size=0.2,shuffle=True,random_state=43)\n",
    "len(train_set),len(val_set)\n",
    "train_loader=DataLoader(train_set, batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader=DataLoader(val_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOW IMAGES WITH THE ACTUAL LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimages(imgs,actual_lbls,pred_lbls=None):\n",
    "  total = 0\n",
    "  good = 0\n",
    "  fig = plt.figure(figsize=(21,12))\n",
    "\n",
    "  for i,img in enumerate(imgs):\n",
    "    total +=1\n",
    "    fig.add_subplot(4,8, i+1)\n",
    "    y=actual_lbls[i]\n",
    "    \n",
    "    if pred_lbls!=None:\n",
    "      y_pre=pred_lbls[i]\n",
    "      title=\"prediction: {0}\\nlabel:{1}\".format(dataset.classes[y],dataset.classes[y_pre])\n",
    "      if dataset.classes[y] == dataset.classes[y_pre]:\n",
    "        good +=1\n",
    "    else: \n",
    "      title=\"Label: {0}\".format(dataset.classes[y])\n",
    "\n",
    "    plt.title(title)\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "  if pred_lbls != None:\n",
    "    print(\"Accuracy: \"+ str((good/total)*100)+ '%')\n",
    "  \n",
    "plt.show()\n",
    "\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "showimages(inputs,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loss_fn,dataloader,optimizer,epoch):\n",
    "  print('\\nEpoch : %d'%epoch)\n",
    "  \n",
    "  total_loss=0    \n",
    "  correct=0\n",
    "  total=0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for data in tqdm(dataloader):\n",
    "    \n",
    "    inputs,labels=data[0].to(device),data[1].to(device)\n",
    "    \n",
    "    outputs=model(inputs)\n",
    "    \n",
    "    loss=loss_fn(outputs,labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "      \n",
    "  loss=total_loss/len(dataloader)\n",
    "  accuracy=100.*correct/total\n",
    "  \n",
    "  accuracies['train'].append(accuracy)\n",
    "  losses['train'].append(loss)\n",
    "  print('Train Loss: %.3f | Accuracy: %.3f'%(loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loss_fn,dataloader,epoch):\n",
    "  model.eval()\n",
    "\n",
    "  total_loss=0\n",
    "  correct=0\n",
    "  total=0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data in tqdm(dataloader):\n",
    "      images,labels=data[0].to(device),data[1].to(device)\n",
    "      \n",
    "      outputs=model(images)\n",
    "\n",
    "      loss= loss_fn(outputs,labels)\n",
    "      total_loss+=loss.item()\n",
    "      \n",
    "      _, predicted = outputs.max(1)\n",
    "      total += labels.size(0)\n",
    "      correct += predicted.eq(labels).sum().item()\n",
    "  \n",
    "  loss=total_loss/len(dataloader)\n",
    "  accuracy=100.*correct/total\n",
    "\n",
    "  losses['val'].append(loss)\n",
    "  accuracies['val'].append(accuracy)\n",
    "\n",
    "  print('Test Loss: %.3f | Accuracy: %.3f'%(loss,accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCH OF TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'train':[], 'val':[]}\n",
    "accuracies = {'train':[], 'val':[]}\n",
    "epochs=20\n",
    "for epoch in range(1,epochs+1): \n",
    "  train(model,loss_fn,train_loader,optimizer_ft,epoch)\n",
    "  test(model,loss_fn,val_loader,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN AND VALIDATION ACCURACY, LOSS SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(accuracies['train'], label='Training Accuracy')\n",
    "plt.plot(accuracies['val'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(losses['train'], label='Training Loss')\n",
    "plt.plot(losses['val'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(model,images,actual_label):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    inputs = images.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    showimages(images,actual_label,preds.cpu())\n",
    "\n",
    "images, classes = next(iter(val_loader))\n",
    "\n",
    "predict_images(model,images,classes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d2d07ecf2d88860f2c138e56ba9f113ddbe5b2c99bcbdd2c585f89a3a040e56"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
